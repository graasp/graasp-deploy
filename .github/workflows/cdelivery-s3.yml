name: Reusable workflow that runs Contiuious Delivery pipeline for S3 deployments

# Control when the action will run.
on:
  # Allow the workflow to be reusable
  workflow_call:
    # Define inputs which can be passed from the caller workflow
    inputs:
      # Specify build folder, if needed
      build-folder:
        required: false
        default: 'build'
        type: string
      # tag: specify tag version to deploy
      tag:
        required: true
        type: string
    # Define secrets which can be passed from the caller workflow
    secrets:
      #aws credentials and variables
      aws-access-key-id:
        required: true
      aws-secret-access-key:
        required: true
      aws-region:
        required: true
      aws-s3-bucket-name:
        required: true
      cloudfront-distribution-id:
        required: true
      #environment variables
      api-host:
        required: false
      port:
        required: false
      show-notifications:
        required: false
      authentication-host:
        required: false
      graasp-compose-host:
        required: false
      graasp-perform-host:
        required: false
      graasp-analyzer-host:
        required: false
      ga-measurement-id:
        required: false
      hidden-item-tag-id:
        required: false
      google-key:
        required: false

# Set environment variables that are available to the steps of all jobs in the workflow
env:
  BUILD_FOLDER: '${{ inputs.build-folder }}'

# This workflow is made up of two jobs that run sequentially, called tebuild-deploy and test
jobs:
  # Build, sync with S3 and deploy to staging environment
  build-deploy:
    name: Build-sync-deploy
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Check-out repository under $GITHUB_WORKSPACE, so the job can access it
    - name: Check out code
      uses: actions/checkout@v2
      with:
        ref: ${{ inputs.tag }}

    # Download and cache distribution of the requested Node.js version, and add it to the PATH
    - name: Setup node
      id: setup-node
      uses: actions/setup-node@v2
      with:
        node-version: '16'
        check-latest: true

    - name: Yarn build staging version
      id: build-image
      # Set environment variables required to perform the build. These are only available to this step
      env: 
        REACT_APP_API_HOST: ${{ secrets.api-host }}
        PORT: ${{ secrets.port }}
        REACT_APP_SHOW_NOTIFICATIONS: ${{ secrets.show-notifications }}
        REACT_APP_AUTHENTICATION_HOST: ${{ secrets.authentication-host }}
        REACT_APP_GRAASP_COMPOSE_HOST: ${{ secrets.graasp-compose-host }}
        REACT_APP_GRAASP_PERFORM_HOST: ${{ secrets.graasp-preform-host }}
        REACT_APP_GRAASP_ANALYZER_HOST: ${{ secrets.graasp-analyzer-host }}
        REACT_APP_GA_MEASUREMENT_ID: ${{ secrets.ga-measurement-id }}
        REACT_APP_HIDDEN_ITEM_TAG_ID: ${{ secrets.hidden-item-tag-id }}
      # Run a set of commands using the runners shell to perform install and build
      run: |
        yarn install
        yarn run build

    # Configure AWS credential and region environment variables for use in next steps
    - name: Configure AWS Credentials
      id: configure-aws
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.aws-access-key-id }}
        aws-secret-access-key: ${{ secrets.aws-secret-access-key }}
        aws-region: ${{ secrets.aws-region }}

    # Recursively copy new and updated files from the source directory to the destination
    - name: Sync files with AWS S3 Bucket
      id: sync-s3
      # Set environment variable with the name of the destination bucket to perform sync. It is only available to this step
      env:
        APP_DIR: '${{ secrets.aws-s3-bucket-name }}'
      run: aws s3 sync ${{env.BUILD_FOLDER}} s3://${APP_DIR} --acl public-read --follow-symlinks --delete
      # --acl public-read makes files publicly readable 
      # --follow-symlinks fixes some weird symbolic link problems that may come up
      # --delete permanently deletes files in the S3 bucket that are not present in the latest version of the repository/build.

    # Create a new invalidation
    - name: Invalidate cloudfront distribution
      id: invalidate-cloudfront
      run: aws cloudfront create-invalidation --distribution-id ${{ secrets.cloudfront-distribution-id }} --paths /*
    
  test:
    name: Test
    needs: build-deploy
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    # The environment that the job will reference
    environment: 
      name: staging
    steps:
    # Check-out repository under $GITHUB_WORKSPACE, so the job can access it
    - name: Check out code
      uses: actions/checkout@v2
      with:
        ref: ${{ inputs.tag }}

    # This step runs a single command to execute integation testing
    - name: Test
      run: |
        echo "This is the integration test step"

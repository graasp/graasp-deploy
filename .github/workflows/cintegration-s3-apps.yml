name: Reusable workflow that runs Continuous Integration pipeline for S3 apps

# Control when the action will run
on:
  # Allow the workflow to be reusable
  workflow_call:
    # Define inputs which can be passed from the caller workflow
    inputs:
      # build-folder: path to build folder inside repository, if needed
      build-folder:
        required: false
        default: 'build'
        type: string
      # version: app version, if needed
      version:
        required: false
        default: 'latest'
        type: string
      api-host-test:
        required: false
        type: string
      enable-mock-api-test:
        required: false
        type: string
      graasp-app-id-test:
        required: false
        type: string
      graasp-domain-test:
        required: false
        type: string
      mock-api-test:
        required: false
        type: string
      node-env-test:
        required: false
        type: string
      test-execution:
        required: false
        type: boolean
        default: true
    # Define secrets which can be passed from the caller workflow
    secrets:
      # AWS credentials and variables
      aws-access-key-id:
        required: true
      aws-secret-access-key:
        required: true
      aws-region:
        required: true
      aws-s3-bucket-name:
        required: true
      cloudfront-distribution-id:
        required: true
      # Environment variables
      app-id:
        required: true
      graasp-domain:
        required: true
      sentry-dsn:
        required: false

# Saving computation time by stopping obsolete workflows
concurrency: 
  group: ${{ github.ref }}
  cancel-in-progress: true

# Set environment variables that are available to the steps of all jobs in the workflow
env:
  BUILD_FOLDER: '${{ inputs.build-folder }}'
  VERSION: '${{ inputs.version }}'
  # Allows to increase Node's max heap size
  NODE_OPTIONS: '--max_old_space_size=8192'

# This workflow is made up of three jobs that run sequentially, called test, build and deploy
jobs:
  # Build and sync with S3
  build:
    name: Build
    runs-on: ubuntu-latest

    steps:
    # Check-out repository under $GITHUB_WORKSPACE, so the job can access it
    - name: Check out code
      uses: actions/checkout@v2

    # Download and cache distribution of the requested Node.js version, and add it to the PATH
    - name: Setup node
      id: setup-node
      uses: actions/setup-node@v2
      with:
        node-version: '16'
        check-latest: true

    # Get the yarn cache path.
    - name: Get yarn cache directory
      id: yarn-cache-dir-path
      run: |
        echo "::set-output name=dir::$(yarn config get cacheFolder)"

    # Cache dependencies to speed up workflow. Only for development branches
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the hashFiles function to create a new cache when dependencies change.
    # restore-keys: An ordered list of alternative keys to use for finding the cache if no cache hit occurred for key
    - name: Cache dependencies
      id: cache-yarn
      uses: actions/cache@v3
      with:
        path: ${{ steps.yarn-cache-dir-path.outputs.dir }}
        key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
        restore-keys: |
          ${{ runner.os }}-yarn-

    # Cache cypress binary to speed up workflow. Only for development branches
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the hashFiles function to create a new cache when dependencies change.
    # To avoid snowballing Cypress binary cache we use the exact key and not the restore keys.
    - name: Cache Cypress Binary
      id: cache-cypress-binary
      uses: actions/cache@v3
      with:
        path: '~/.cache/Cypress'
        key: ${{ runner.os }}-cypress-binary-${{ hashFiles('**/yarn.lock') }}

    # Install dependencies
    # The --cached flag with 'yarn add' is used  to use cached downloads (in the cache directory mentioned above) 
    # during installation whenever possible instead of downloading them.
    - name: Install dependencies
      id: install
      run: yarn add --cached

    - name: Yarn build dev
      id: build-image
      # Set environment variables required to perform the build. These are only available to this step
      env: 
        REACT_APP_GRAASP_DOMAIN: ${{ secrets.graasp-domain }}
        REACT_APP_GRAASP_APP_ID: ${{ secrets.app-id }}
        REACT_APP_SENTRY_DSN: ${{ secrets.sentry-dsn }}
        REACT_APP_MOCK_API: false
      # Run a set of commands using the runners shell to perform install and build
      run: yarn run build

    # Cache build to share it between jobs
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the branch and run_id to create a new build for every run.
    - name: Cache build
      id: cache-build
      uses: actions/cache@v3
      with:
        path: build
        key: ${{ runner.os }}-build-${{ github.ref_name }}-${{ github.run_id }}

  test:
    name: Test
    needs: build
    # This job is executed only when the user manually selects this option. If not, the code will be deployed without testing.
    if: ${{ (inputs.test-execution == true) ||  (github.event_name == 'push') }}
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Check-out repository under $GITHUB_WORKSPACE, so the job can access it
    - name: Check out code
      uses: actions/checkout@v3

    # Download and cache distribution of the requested Node.js version, and add it to the PATH
    - name: Setup node
      id: setup-node
      uses: actions/setup-node@v3
      with:
        node-version: '16'
        check-latest: true

    # Get the yarn cache path.
    - name: Get yarn cache directory
      id: yarn-cache-dir-path
      run: |
        echo "::set-output name=dir::$(yarn config get cacheFolder)"

    # Cache dependencies to speed up workflow. Only for development branches
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the hashFiles function to create a new cache when dependencies change.
    # restore-keys: An ordered list of alternative keys to use for finding the cache if no cache hit occurred for key
    - name: Cache dependencies
      id: cache-yarn
      uses: actions/cache@v3
      with:
        path: ${{ steps.yarn-cache-dir-path.outputs.dir }}
        key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
        restore-keys: |
          ${{ runner.os }}-yarn-

    # Cache cypress binary to speed up workflow
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the hashFiles function to create a new cache when dependencies change.
    # restore-keys: An ordered list of alternative keys to use for finding the cache if no cache hit occurred for key
    - name: Cache Cypress Binary
      id: cache-cypress-binary
      uses: actions/cache@v3
      with:
        path: '~/.cache/Cypress'
        key: ${{ runner.os }}-cypress-binary-${{ hashFiles('**/yarn.lock') }}

    # Install dependencies
    - name: Install dependencies
      id: install
      run: yarn add --cached

    #  use the Cypress GitHub Action to run Cypress tests within the chrome browser
    - name: Cypress run
      uses: cypress-io/github-action@v4
      with:
        install: false
        config: baseUrl=http://localhost:3000
        start: yarn start:ci
        wait-on: 'http://localhost:3000'
        wait-on-timeout: 180
        browser: chrome
        quiet: true
      env:
        REACT_APP_API_HOST: ${{ inputs.api-host-test }}
        REACT_APP_ENABLE_MOCK_API: ${{ inputs.enable-mock-api-test }}
        REACT_APP_GRAASP_APP_ID: ${{ inputs.graasp-app-id-test }}
        REACT_APP_GRAASP_DOMAIN: ${{ inputs.graasp-domain-test }}
        REACT_APP_MOCK_API: ${{ inputs.mock-api-test }}
        NODE_ENV: ${{ inputs.node-env-test}}

    # after the test run completes
    # store any screenshots
    # NOTE: screenshots will be generated only if E2E test failed
    # thus we store screenshots only on failures
    - uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: cypress-screenshots
        path: cypress/screenshots

    - name: coverage report
      run: npx nyc report --reporter=text-summary

  # Deploy to development environment
  deploy: 
    name: Deploy
    needs: [build, test]
    # This job is executed only when the build job has been successful and either the user has manually dispatched the workflow or it is a push to the default branch (main or master). 
    if: ${{ always() && needs.build.result == 'success' && ((github.event_name == 'workflow_dispatch') || (github.ref_name == 'main') || (github.ref_name == 'master')) }}
    runs-on: ubuntu-latest

    steps:
    # Cache build to re-use it from previous jobs
    - name: Cache build
      id: cache-build
      uses: actions/cache@v3
      with:
        path: build
        key: ${{ runner.os }}-build-${{ github.ref_name }}-${{ github.run_id }}

    # Configure AWS credential and region environment variables for use in next steps
    - name: Configure AWS Credentials
      id: configure-aws
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.aws-access-key-id }}
        aws-secret-access-key: ${{ secrets.aws-secret-access-key }}
        aws-region: ${{ secrets.aws-region }}

    # Recursively copy new and updated files from the source directory to the destination
    - name: Sync files with AWS S3 Bucket
      id: sync-s3
      # Set environment variable with the name of the destination bucket to perform sync. It is only available to this step
      env:
        APP_DIR: '${{ secrets.aws-s3-bucket-name }}/${{ secrets.app-id }}/${{env.VERSION}}/'
      run: aws s3 sync ${{env.BUILD_FOLDER}} s3://${APP_DIR} --acl public-read --follow-symlinks --delete
      # --acl public-read makes files publicly readable 
      # --follow-symlinks fixes some weird symbolic link problems that may come up
      # --delete permanently deletes files in the S3 bucket that are not present in the latest version of the repository/build.


    # Create a new invalidation
    - name: Invalidate cloudfront distribution
      id: invalidate-cloudfront
      run: aws cloudfront create-invalidation --distribution-id ${{ secrets.cloudfront-distribution-id }} --paths /${{ secrets.app-id }}/${{env.VERSION}}/*

name: Reusable workflow that runs Continuous Integration pipeline for S3 apps

# Control when the action will run
on:
  # Allow the workflow to be reusable
  workflow_call:
    # Define inputs which can be passed from the caller workflow
    inputs:
      # build-folder: path to build folder inside repository, if needed
      build-folder:
        required: false
        default: 'build'
        type: string
      # version: app version, if needed
      version:
        required: false
        default: 'latest'
        type: string
    # Define secrets which can be passed from the caller workflow
    secrets:
      # AWS credentials and variables
      aws-access-key-id:
        required: true
      aws-secret-access-key:
        required: true
      aws-region:
        required: true
      aws-s3-bucket-name:
        required: true
      cloudfront-distribution-id:
        required: true
      # Environment variables
      app-id:
        required: true
      graasp-domain:
        required: true
      sentry-dsn:
        required: false

# Set environment variables that are available to the steps of all jobs in the workflow
env:
  BUILD_FOLDER: '${{ inputs.build-folder }}'
  VERSION: '${{ inputs.version }}'
  # Allows to increase Node's max heap size
  NODE_OPTIONS: '--max_old_space_size=8192'

# This workflow is made up of three jobs that run sequentially, called test, build and deploy
jobs:
  # Build and sync with S3
  build:
    name: Build
    runs-on: ubuntu-latest

    steps:
    # Check-out repository under $GITHUB_WORKSPACE, so the job can access it
    - name: Check out code
      uses: actions/checkout@v2

    # Download and cache distribution of the requested Node.js version, and add it to the PATH
    - name: Setup node
      id: setup-node
      uses: actions/setup-node@v2
      with:
        node-version: '16'
        check-latest: true

    # Cache dependencies to speed up workflow. Only for development branches
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the hashFiles function to create a new cache when dependencies change.
    # restore-keys: An ordered list of alternative keys to use for finding the cache if no cache hit occurred for key
    - name: Cache dependencies
      id: cache-node-modules
      if: (github.ref_name != 'main') && (github.ref_name != 'master')
      uses: actions/cache@v3
      with:
        path: '**/node_modules'
        key: ${{ runner.os }}-modules-${{ hashFiles('**/yarn.lock') }}
        restore-keys: |
            ${{ runner.os }}-modules-

    # Install dependencies when the cache has not been retrieved
    - name: Install dependencies
      id: install
      if: steps.cache-node-modules.outputs.cache-hit != 'true'
      run: yarn install

    - name: Yarn build dev
      id: build-image
      # Set environment variables required to perform the build. These are only available to this step
      env: 
        REACT_APP_GRAASP_DOMAIN: ${{ secrets.graasp-domain }}
        REACT_APP_GRAASP_APP_ID: ${{ secrets.app-id }}
        REACT_APP_SENTRY_DSN: ${{ secrets.sentry-dsn }}
        REACT_APP_MOCK_API: false
      # Run a set of commands using the runners shell to perform install and build
      run: yarn run build

    # Cache build to share it between jobs
    # path: The file path on the runner to cache or restore.
    # key: Create cache key using the branch and run_id to create a new build for every run.
    - name: Cache build
      id: cache-build
      uses: actions/cache@v3
      with:
        path: build
        key: ${{ runner.os }}-build-${{ github.ref_name }}-${{ github.run_id }}

  # Deploy to development environment
  deploy: 
    needs: build
    name: Deploy
    runs-on: ubuntu-latest

    steps:
    # Cache build to re-use it from previous jobs
    - name: Cache build
      id: cache-build
      uses: actions/cache@v3
      with:
        path: build
        key: ${{ runner.os }}-build-${{ github.ref_name }}-${{ github.run_id }}

    # Configure AWS credential and region environment variables for use in next steps
    - name: Configure AWS Credentials
      id: configure-aws
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.aws-access-key-id }}
        aws-secret-access-key: ${{ secrets.aws-secret-access-key }}
        aws-region: ${{ secrets.aws-region }}

    # Recursively copy new and updated files from the source directory to the destination
    - name: Sync files with AWS S3 Bucket
      id: sync-s3
      # Set environment variable with the name of the destination bucket to perform sync. It is only available to this step
      env:
        APP_DIR: '${{ secrets.aws-s3-bucket-name }}/${{ secrets.app-id }}/${{env.VERSION}}/'
      run: aws s3 sync ${{env.BUILD_FOLDER}} s3://${APP_DIR} --acl public-read --follow-symlinks --delete
      # --acl public-read makes files publicly readable 
      # --follow-symlinks fixes some weird symbolic link problems that may come up
      # --delete permanently deletes files in the S3 bucket that are not present in the latest version of the repository/build.


    # Create a new invalidation
    - name: Invalidate cloudfront distribution
      id: invalidate-cloudfront
      run: aws cloudfront create-invalidation --distribution-id ${{ secrets.cloudfront-distribution-id }} --paths /${{ secrets.app-id }}/${{env.VERSION}}/*
